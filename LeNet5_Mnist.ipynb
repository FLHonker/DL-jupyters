{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-18T08:34:17.664893Z",
     "start_time": "2019-04-18T08:34:10.740387Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "import argparse\n",
    "import matplotlib as plt\n",
    "\n",
    "# training settings\n",
    "batch_size = 64 \n",
    "lr = 0.001 \n",
    "n_epoch = 5\n",
    "\n",
    "# 定义是否使用GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# MNSIT dataset\n",
    "train_dataset = datasets.MNIST(root='./data/', \n",
    "                               train=True,\n",
    "                               transform=transforms.ToTensor(),\n",
    "                               download=False\n",
    "                              )\n",
    "\n",
    "test_dataset = datasets.MNIST(root='./data/',\n",
    "                              train=False,\n",
    "                              transform=transforms.ToTensor()\n",
    "                             )\n",
    "\n",
    "# data loader (input pipeline)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True\n",
    "                                          )\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=False\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-18T08:34:23.637337Z",
     "start_time": "2019-04-18T08:34:23.630459Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# 定义网络结构\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Sequential(  # input_size=(1*28*28)\n",
    "            nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),   # input_size=(6*28*28)\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # output_size=(6*14*14)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(6, 16, kernel_size=5),\n",
    "            nn.ReLU(),  # input_szie=(16*10*10)\n",
    "            nn.MaxPool2d(2, 2),  # output_szie=(16*5*5)\n",
    "        )\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(16 * 5 * 5, 120),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(120, 84),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.fc3 = nn.Linear(84, 10) \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x) \n",
    "        # nn.Linear()的输入输出都是维度为一的值，所以要把多维度的tensor展平成一维 \n",
    "        x = x.view(x.size()[0], -1) \n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x) \n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-15T12:01:03.686279Z",
     "start_time": "2019-04-15T12:01:03.682487Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--outf OUTF] [--net NET]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /run/user/1005/jupyter/kernel-6bbe65c2-9a45-464d-8c2e-29ab11a5c8cd.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "# # 命令行参数设置\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('--outf', default='./model/', help='folder to output images and model checkpoints') #模型保存路径\n",
    "# parser.add_argument('--net', default='./model/net.pth', help=\"path to netG (to continue training)\")  #模型加载路径\n",
    "# opt = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-18T08:34:32.905204Z",
     "start_time": "2019-04-18T08:34:30.133574Z"
    }
   },
   "outputs": [],
   "source": [
    "# 定义损失函数loss function 和优化方式（采用SGD）\n",
    "net = LeNet().to(device)\n",
    "criterion = nn.CrossEntropyLoss()  # 交叉熵损失函数，通常用于多分类问题上\n",
    "optimizer = optim.SGD(net.parameters(), lr=lr, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-18T08:35:12.926330Z",
     "start_time": "2019-04-18T08:34:35.715299Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 - 0/938\tLoss:0.023034\n",
      "epoch:0 - 100/938\tLoss:2.301380\n",
      "epoch:0 - 200/938\tLoss:2.297725\n",
      "epoch:0 - 300/938\tLoss:2.292021\n",
      "epoch:0 - 400/938\tLoss:2.285759\n",
      "epoch:0 - 500/938\tLoss:2.273999\n",
      "epoch:0 - 600/938\tLoss:2.248425\n",
      "epoch:0 - 700/938\tLoss:2.175310\n",
      "epoch:0 - 800/938\tLoss:1.893731\n",
      "epoch:0 - 900/938\tLoss:1.113367\n",
      "第0个epoch的识别准确率为：80.000%\n",
      "epoch:1 - 0/938\tLoss:0.007317\n",
      "epoch:1 - 100/938\tLoss:0.613155\n",
      "epoch:1 - 200/938\tLoss:0.499569\n",
      "epoch:1 - 300/938\tLoss:0.419155\n",
      "epoch:1 - 400/938\tLoss:0.410327\n",
      "epoch:1 - 500/938\tLoss:0.373323\n",
      "epoch:1 - 600/938\tLoss:0.345462\n",
      "epoch:1 - 700/938\tLoss:0.337054\n",
      "epoch:1 - 800/938\tLoss:0.301597\n",
      "epoch:1 - 900/938\tLoss:0.290528\n",
      "第1个epoch的识别准确率为：91.000%\n",
      "epoch:2 - 0/938\tLoss:0.001744\n",
      "epoch:2 - 100/938\tLoss:0.261486\n",
      "epoch:2 - 200/938\tLoss:0.275710\n",
      "epoch:2 - 300/938\tLoss:0.241693\n",
      "epoch:2 - 400/938\tLoss:0.242607\n",
      "epoch:2 - 500/938\tLoss:0.224495\n",
      "epoch:2 - 600/938\tLoss:0.203622\n",
      "epoch:2 - 700/938\tLoss:0.218823\n",
      "epoch:2 - 800/938\tLoss:0.196999\n",
      "epoch:2 - 900/938\tLoss:0.211363\n",
      "第2个epoch的识别准确率为：95.000%\n",
      "epoch:3 - 0/938\tLoss:0.001684\n",
      "epoch:3 - 100/938\tLoss:0.181572\n",
      "epoch:3 - 200/938\tLoss:0.174760\n",
      "epoch:3 - 300/938\tLoss:0.186117\n",
      "epoch:3 - 400/938\tLoss:0.164531\n",
      "epoch:3 - 500/938\tLoss:0.172426\n",
      "epoch:3 - 600/938\tLoss:0.159334\n",
      "epoch:3 - 700/938\tLoss:0.137917\n",
      "epoch:3 - 800/938\tLoss:0.151503\n",
      "epoch:3 - 900/938\tLoss:0.154336\n",
      "第3个epoch的识别准确率为：96.000%\n",
      "epoch:4 - 0/938\tLoss:0.001383\n",
      "epoch:4 - 100/938\tLoss:0.141345\n",
      "epoch:4 - 200/938\tLoss:0.137509\n",
      "epoch:4 - 300/938\tLoss:0.139756\n",
      "epoch:4 - 400/938\tLoss:0.137410\n",
      "epoch:4 - 500/938\tLoss:0.128074\n",
      "epoch:4 - 600/938\tLoss:0.131434\n",
      "epoch:4 - 700/938\tLoss:0.124822\n",
      "epoch:4 - 800/938\tLoss:0.142321\n",
      "epoch:4 - 900/938\tLoss:0.118325\n",
      "第4个epoch的识别准确率为：96.000%\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "if __name__ == '__main__':\n",
    "    for epoch in range(n_epoch):\n",
    "        sum_loss = 0.0\n",
    "        for idx, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            # forward + backward\n",
    "            outputs = net.forward(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # 每训练100个batch打印一次平均loss\n",
    "            sum_loss += loss.item()\n",
    "            if idx % 100 == 0: \n",
    "                print('epoch:{} - {}/{}\\tLoss:{:.6f}'.format(epoch, idx, len(train_loader), sum_loss / 100))\n",
    "                sum_loss = 0\n",
    "        \n",
    "        # 每跑完一次epoch测试一下准确率\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = net.forward(images)\n",
    "                # 取得分最高的类\n",
    "                _, pred = torch.max(outputs.data, 1) \n",
    "                total += labels.size(0)\n",
    "                correct += (pred == labels).sum()\n",
    "        \n",
    "        print('第{}个epoch的识别准确率为：{:.3f}%'.format(epoch, 100.0 * correct / total))\n",
    "    torch.save(net.state_dict(), '{}/net_{}.pth'.format('./models', epoch))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37] *",
   "language": "python",
   "name": "conda-env-py37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
