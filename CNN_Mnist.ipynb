{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN\n",
    "\n",
    "卷积神经网络CNN的结构一般包含这几个层： \n",
    "**输入层**：用于数据的输入。\n",
    "**卷积层**：使用卷积核进行特征提取和特征映射。\n",
    "**激励层**：由于卷积也是一种线性运算，因此需要增加非线性映射。\n",
    "**池化层**：进行下采样，对特征图稀疏处理，减少数据运算量。 \n",
    "**全连接层**：通常在CNN的尾部进行重新拟合，减少特征信息的损失。\n",
    "**输出层**：用于输出结果。\n",
    "\n",
    "## architecture\n",
    "\n",
    "![CNN.png](https://img-blog.csdn.net/20180211155818513?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbTBfMzczMDYzNjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-15T09:50:30.279507Z",
     "start_time": "2019-04-15T09:50:30.257255Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets,transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# training settings\n",
    "batch_size = 64 \n",
    "\n",
    "# MNSIT dataset\n",
    "train_dataset = datasets.MNIST(root='./data/', \n",
    "                               train=True,\n",
    "                               transform=transforms.ToTensor(),\n",
    "                               download=False\n",
    "                              )\n",
    "\n",
    "test_dataset = datasets.MNIST(root='./data/',\n",
    "                              train=False,\n",
    "                              transform=transforms.ToTensor()\n",
    "                             )\n",
    "\n",
    "# data loader (input pipeline)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True\n",
    "                                          )\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-15T09:12:49.586280Z",
     "start_time": "2019-04-15T09:12:49.582634Z"
    }
   },
   "outputs": [],
   "source": [
    "# CNN Net\n",
    "class CNNNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.mp = nn.MaxPool2d(2)\n",
    "        self.fc = nn.Linear(320, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # in_size = 64\n",
    "        in_size = x.size(0) # one batch\n",
    "        # x:64*10*12*12\n",
    "        x = F.relu(self.mp(self.conv1(x)))\n",
    "        # x:64*20*4*4\n",
    "        x = F.relu(self.mp(self.conv2(x)))\n",
    "        # x:64*3200\n",
    "        x = x.view(in_size, -1) # flatten the tensor\n",
    "        # x:64*10\n",
    "        x = self.fc(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-15T09:14:51.493440Z",
     "start_time": "2019-04-15T09:14:51.479798Z"
    }
   },
   "outputs": [],
   "source": [
    "model = CNNNet()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-15T09:51:07.360996Z",
     "start_time": "2019-04-15T09:51:07.357881Z"
    }
   },
   "outputs": [],
   "source": [
    "# train\n",
    "def train(epoch):\n",
    "    for batch_idx,(data, target) in enumerate(train_loader):\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 200 == 0:\n",
    "            print('Train epoch:{} {}/{}({:.0f}%)\\tLoss:{:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-15T09:55:26.029687Z",
     "start_time": "2019-04-15T09:55:26.025029Z"
    }
   },
   "outputs": [],
   "source": [
    "# test\n",
    "def test():\n",
    "    test_loss = 0\n",
    "    correct = 0 \n",
    "    for data, target in test_loader:\n",
    "        with torch.no_grad():\n",
    "            data, target = Variable(data), Variable(target)\n",
    "            output = model(data)\n",
    "            # sum up batch loss\n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "            # get the index of the max log-probability\n",
    "            pred = output.data.max(1)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "        \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-15T10:07:22.449169Z",
     "start_time": "2019-04-15T10:06:01.035059Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNNNet(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (mp): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc): Linear(in_features=320, out_features=10, bias=True)\n",
      ")\n",
      "Train epoch:1 0/60000(0%)\tLoss:0.022435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yaliu/Dev/anaconda3/envs/py37/lib/python3.7/site-packages/ipykernel_launcher.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch:1 12800/60000(21%)\tLoss:0.048499\n",
      "Train epoch:1 25600/60000(43%)\tLoss:0.002146\n",
      "Train epoch:1 38400/60000(64%)\tLoss:0.018301\n",
      "Train epoch:1 51200/60000(85%)\tLoss:0.008258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yaliu/Dev/anaconda3/envs/py37/lib/python3.7/site-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0405, Accuracy: 9863/10000 (98%)\n",
      "\n",
      "Train epoch:2 0/60000(0%)\tLoss:0.005861\n",
      "Train epoch:2 12800/60000(21%)\tLoss:0.024455\n",
      "Train epoch:2 25600/60000(43%)\tLoss:0.016191\n",
      "Train epoch:2 38400/60000(64%)\tLoss:0.060093\n",
      "Train epoch:2 51200/60000(85%)\tLoss:0.239747\n",
      "\n",
      "Test set: Average loss: 0.0369, Accuracy: 9884/10000 (98%)\n",
      "\n",
      "Train epoch:3 0/60000(0%)\tLoss:0.017807\n",
      "Train epoch:3 12800/60000(21%)\tLoss:0.003735\n",
      "Train epoch:3 25600/60000(43%)\tLoss:0.000745\n",
      "Train epoch:3 38400/60000(64%)\tLoss:0.022618\n",
      "Train epoch:3 51200/60000(85%)\tLoss:0.019368\n",
      "\n",
      "Test set: Average loss: 0.0381, Accuracy: 9865/10000 (98%)\n",
      "\n",
      "Train epoch:4 0/60000(0%)\tLoss:0.004647\n",
      "Train epoch:4 12800/60000(21%)\tLoss:0.048421\n",
      "Train epoch:4 25600/60000(43%)\tLoss:0.036511\n",
      "Train epoch:4 38400/60000(64%)\tLoss:0.004348\n",
      "Train epoch:4 51200/60000(85%)\tLoss:0.003322\n",
      "\n",
      "Test set: Average loss: 0.0389, Accuracy: 9870/10000 (98%)\n",
      "\n",
      "Train epoch:5 0/60000(0%)\tLoss:0.003027\n",
      "Train epoch:5 12800/60000(21%)\tLoss:0.007592\n",
      "Train epoch:5 25600/60000(43%)\tLoss:0.035707\n",
      "Train epoch:5 38400/60000(64%)\tLoss:0.087975\n",
      "Train epoch:5 51200/60000(85%)\tLoss:0.115401\n",
      "\n",
      "Test set: Average loss: 0.0369, Accuracy: 9874/10000 (98%)\n",
      "\n",
      "Train epoch:6 0/60000(0%)\tLoss:0.023789\n",
      "Train epoch:6 12800/60000(21%)\tLoss:0.015948\n",
      "Train epoch:6 25600/60000(43%)\tLoss:0.042151\n",
      "Train epoch:6 38400/60000(64%)\tLoss:0.031107\n",
      "Train epoch:6 51200/60000(85%)\tLoss:0.000851\n",
      "\n",
      "Test set: Average loss: 0.0394, Accuracy: 9870/10000 (98%)\n",
      "\n",
      "Train epoch:7 0/60000(0%)\tLoss:0.005804\n",
      "Train epoch:7 12800/60000(21%)\tLoss:0.035229\n",
      "Train epoch:7 25600/60000(43%)\tLoss:0.014561\n",
      "Train epoch:7 38400/60000(64%)\tLoss:0.038175\n",
      "Train epoch:7 51200/60000(85%)\tLoss:0.004465\n",
      "\n",
      "Test set: Average loss: 0.0380, Accuracy: 9880/10000 (98%)\n",
      "\n",
      "Train epoch:8 0/60000(0%)\tLoss:0.025698\n",
      "Train epoch:8 12800/60000(21%)\tLoss:0.022581\n",
      "Train epoch:8 25600/60000(43%)\tLoss:0.011980\n",
      "Train epoch:8 38400/60000(64%)\tLoss:0.023031\n",
      "Train epoch:8 51200/60000(85%)\tLoss:0.014865\n",
      "\n",
      "Test set: Average loss: 0.0432, Accuracy: 9865/10000 (98%)\n",
      "\n",
      "Train epoch:9 0/60000(0%)\tLoss:0.014158\n",
      "Train epoch:9 12800/60000(21%)\tLoss:0.068931\n",
      "Train epoch:9 25600/60000(43%)\tLoss:0.026888\n",
      "Train epoch:9 38400/60000(64%)\tLoss:0.006434\n",
      "Train epoch:9 51200/60000(85%)\tLoss:0.064700\n",
      "\n",
      "Test set: Average loss: 0.0394, Accuracy: 9874/10000 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "for epoch in range(1, 10):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
